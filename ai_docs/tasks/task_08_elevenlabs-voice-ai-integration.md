# Bolt.new Agent Prompt: Phase 8 â€“ ElevenLabs Voice AI Integration

## Prompt

You are an expert AI accessibility and multimodal experience engineer working in Bolt.new. Your task is to integrate ElevenLabs Voice AI into the AgriConnect platform, ensuring advanced text-to-speech (TTS) and voice notification capabilities for accessibility and next-generation user experience.

**Instructions:**

1. **ElevenLabs Integration**
   - Integrate ElevenLabs Voice AI for text-to-speech (TTS) and voice notifications across all relevant user interfaces and agent workflows.
   - Ensure accessibility for users in rural or low-literacy contexts by providing natural-sounding voice for agent responses and notifications.
   - Make voice features configurable per user or agent, with support for multiple languages and voices.
   - Ensure the integration is modular and can be enabled/disabled as needed, with fallback to text-only if TTS is unavailable.
   - Support multimodal (text and voice) user experiences throughout the platform.

2. **Testing and Documentation**
   - Write tests to validate that all notifications and agent responses can be delivered as both text and natural-sounding voice.
   - Output all integration code, configuration, and technical documentation in markdown, ready to be committed to the codebase.

**Validation:**
- Ensure ElevenLabs Voice AI is fully integrated, modular, and configurable, providing accessible and multimodal user experiences as described.

---

**Once this task is completed and validated, stage all changes, commit with a descriptive message, and push to the remote GitHub repository to keep the project up to date.** 